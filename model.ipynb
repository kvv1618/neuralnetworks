{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Climate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "climate_df = pd.read_csv('data/climate_data.csv')\n",
    "climate_df['date'] = pd.to_datetime(climate_df['date'])\n",
    "climate_df.index = climate_df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "numeric_cols = climate_df.select_dtypes(include=['float64', 'int64']).columns.to_list()\n",
    "numeric_cols.remove('lat')\n",
    "numeric_cols.remove('lon')\n",
    "non_numeric_cols = climate_df.select_dtypes(exclude=['float64', 'int64']).columns.to_list() + ['lat', 'lon']\n",
    "\n",
    "climate_df[numeric_cols] = climate_df[numeric_cols].astype(float)\n",
    "climate_df[non_numeric_cols] = climate_df[non_numeric_cols]\n",
    "scaler = MinMaxScaler()\n",
    "scaled_df = pd.DataFrame(scaler.fit_transform(climate_df[numeric_cols]), columns=numeric_cols, index=climate_df.index)\n",
    "\n",
    "climate_data = pd.concat([scaled_df, climate_df[non_numeric_cols]], axis=1).reset_index(drop= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Energy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_df = pd.read_csv('data/long_data_.csv')\n",
    "energy_df['Dates'] = pd.to_datetime(energy_df['Dates'], format='%d/%m/%Y %H:%M:%S')\n",
    "energy_df.index = energy_df['Dates']\n",
    "\n",
    "redundant_cols = [\"Regions\"]\n",
    "energy_df = energy_df.drop(columns=redundant_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = energy_df.select_dtypes(include=['float64', 'int64']).columns.to_list()\n",
    "numeric_cols.remove('latitude')\n",
    "numeric_cols.remove('longitude')\n",
    "non_numeric_cols = energy_df.select_dtypes(exclude=['float64', 'int64']).columns.to_list() + ['latitude', 'longitude']\n",
    "energy_df[numeric_cols] = energy_df[numeric_cols].astype(float)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_df = pd.DataFrame(scaler.fit_transform(energy_df[numeric_cols]), columns=numeric_cols, index=energy_df.index)\n",
    "energy_data = pd.concat([scaled_df, energy_df[non_numeric_cols]], axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State-Lat-Lon Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "lat_range = np.array([10, 14, 18, 22, 26, 30, 34])\n",
    "lon_range = np.array([72, 76, 80, 84, 88])\n",
    "\n",
    "energy_data[\"latitude\"] = energy_data[\"latitude\"].apply(lambda x: lat_range[np.argmin(np.abs(lat_range - x))])\n",
    "energy_data[\"longitude\"] = energy_data[\"longitude\"].apply(lambda x: lon_range[np.argmin(np.abs(lon_range - x))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreTrain on Climate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-Series Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def lagged_climate_input(data, seq_length=28):\n",
    "    X = []\n",
    "    for _, group in data.groupby([\"lat\", \"lon\"]):\n",
    "        group = group.sort_values(\"date\")\n",
    "        features = group.drop(columns=[\"date\", \"lat\", \"lon\"])\n",
    "        for row in range(len(features) - seq_length):\n",
    "            X.append(features.iloc[row:row+seq_length].values)\n",
    "    return np.array(X)\n",
    "\n",
    "climate_X = lagged_climate_input(climate_data, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ClimatePreTrainer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=1):\n",
    "        super(ClimatePreTrainer, self).__init__()\n",
    "        self.encoder = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
    "        self.decoder = nn.LSTM(hidden_size * 2, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, input_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded_x, _ = self.encoder(x)\n",
    "        decoded_x, _ = self.decoder(encoded_x)\n",
    "        reconstructed_x = self.fc(decoded_x)\n",
    "        return reconstructed_x\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "ClimatePreTrainer(\n",
      "  (encoder): LSTM(11, 64, batch_first=True, bidirectional=True)\n",
      "  (decoder): LSTM(128, 64, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=128, out_features=11, bias=True)\n",
      ")\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "ClimatePreTrainer                        [14, 11]                  --\n",
      "├─LSTM: 1-1                              [14, 128]                 39,424\n",
      "├─LSTM: 1-2                              [14, 128]                 99,328\n",
      "├─Linear: 1-3                            [14, 11]                  1,419\n",
      "==========================================================================================\n",
      "Total params: 140,171\n",
      "Trainable params: 140,171\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 248.66\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.03\n",
      "Params size (MB): 0.56\n",
      "Estimated Total Size (MB): 0.59\n",
      "==========================================================================================\n",
      "Epoch [1/1], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchinfo import summary\n",
    "\n",
    "num_epochs = 1\n",
    "batch_size = 32\n",
    "lr = 0.001\n",
    "\n",
    "climate_X_tensor = torch.tensor(climate_X, dtype=torch.float32)\n",
    "train_dataset = TensorDataset(climate_X_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "climate_pretrained_model = ClimatePreTrainer(input_size=climate_X.shape[2]).to(device)\n",
    "print(\"Model Summary:\")\n",
    "print(climate_pretrained_model)\n",
    "print(summary(climate_pretrained_model, (14, climate_X.shape[2])))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(climate_pretrained_model.parameters(), lr=lr)\n",
    "climate_pretrained_model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "        batch = batch[0].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = climate_pretrained_model(batch)\n",
    "        loss = criterion(outputs, batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "with open('climate_pretrained_climate_pretrained_model.pkl', 'wb') as f:\n",
    "    pickle.dump(climate_pretrained_model, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FineTune Downstream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge DataSources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data[\"month\"] = climate_data[\"date\"].dt.month\n",
    "climate_data[\"year\"] = climate_data[\"date\"].dt.year\n",
    "climate_data = climate_data.drop(columns=[\"date\"])\n",
    "climate_monthly = climate_data.groupby([\"lat\", \"lon\", \"year\", \"month\"]).mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_data[\"month\"] = energy_data[\"Dates\"].dt.month\n",
    "energy_data[\"year\"] = energy_data[\"Dates\"].dt.year\n",
    "energy_data = energy_data.drop(columns=[\"Dates\"])\n",
    "\n",
    "energy_data = energy_data.rename(columns={\"latitude\": \"lat\", \"longitude\": \"lon\"})\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    energy_data,\n",
    "    climate_monthly,\n",
    "    how=\"left\",\n",
    "    left_on=[\"lat\", \"lon\", \"year\", \"month\"],\n",
    "    right_on=[\"lat\", \"lon\", \"year\", \"month\"],\n",
    "    suffixes=(\"\", \"_climate\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "categorical_cols = merged_df.select_dtypes(include=[\"object\"]).columns\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    merged_df[col] = le.fit_transform(merged_df[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usage</th>\n",
       "      <th>States</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>temperature_2m_max</th>\n",
       "      <th>temperature_2m_min</th>\n",
       "      <th>sunshine_duration</th>\n",
       "      <th>rain_sum</th>\n",
       "      <th>snowfall_sum</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>apparent_temperature_max</th>\n",
       "      <th>apparent_temperature_min</th>\n",
       "      <th>precipitation_hours</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>apparent_temperature_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.229207</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.249138</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.448064</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.163856</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.600997</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16594</th>\n",
       "      <td>0.004216</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>88</td>\n",
       "      <td>12</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16595</th>\n",
       "      <td>0.010540</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>88</td>\n",
       "      <td>12</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16596</th>\n",
       "      <td>0.002491</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>88</td>\n",
       "      <td>12</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16597</th>\n",
       "      <td>0.003450</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>88</td>\n",
       "      <td>12</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16598</th>\n",
       "      <td>0.005749</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>88</td>\n",
       "      <td>12</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16599 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Usage  States  lat  lon  month  year  temperature_2m_max  \\\n",
       "0      0.229207      24   30   76      1  2019                 NaN   \n",
       "1      0.249138      11   30   76      1  2019                 NaN   \n",
       "2      0.448064      25   26   76      1  2019                 NaN   \n",
       "3      0.163856       7   30   76      1  2019                 NaN   \n",
       "4      0.600997      30   26   80      1  2019                 NaN   \n",
       "...         ...     ...  ...  ...    ...   ...                 ...   \n",
       "16594  0.004216      18   26   88     12  2020                 NaN   \n",
       "16595  0.010540      19   26   88     12  2020                 NaN   \n",
       "16596  0.002491      20   22   88     12  2020                 NaN   \n",
       "16597  0.003450      21   26   88     12  2020                 NaN   \n",
       "16598  0.005749      29   22   88     12  2020                 NaN   \n",
       "\n",
       "       temperature_2m_min  sunshine_duration  rain_sum  snowfall_sum  \\\n",
       "0                     NaN                NaN       NaN           NaN   \n",
       "1                     NaN                NaN       NaN           NaN   \n",
       "2                     NaN                NaN       NaN           NaN   \n",
       "3                     NaN                NaN       NaN           NaN   \n",
       "4                     NaN                NaN       NaN           NaN   \n",
       "...                   ...                ...       ...           ...   \n",
       "16594                 NaN                NaN       NaN           NaN   \n",
       "16595                 NaN                NaN       NaN           NaN   \n",
       "16596                 NaN                NaN       NaN           NaN   \n",
       "16597                 NaN                NaN       NaN           NaN   \n",
       "16598                 NaN                NaN       NaN           NaN   \n",
       "\n",
       "       precipitation_sum  apparent_temperature_max  apparent_temperature_min  \\\n",
       "0                    NaN                       NaN                       NaN   \n",
       "1                    NaN                       NaN                       NaN   \n",
       "2                    NaN                       NaN                       NaN   \n",
       "3                    NaN                       NaN                       NaN   \n",
       "4                    NaN                       NaN                       NaN   \n",
       "...                  ...                       ...                       ...   \n",
       "16594                NaN                       NaN                       NaN   \n",
       "16595                NaN                       NaN                       NaN   \n",
       "16596                NaN                       NaN                       NaN   \n",
       "16597                NaN                       NaN                       NaN   \n",
       "16598                NaN                       NaN                       NaN   \n",
       "\n",
       "       precipitation_hours  temperature_2m_mean  apparent_temperature_mean  \n",
       "0                      NaN                  NaN                        NaN  \n",
       "1                      NaN                  NaN                        NaN  \n",
       "2                      NaN                  NaN                        NaN  \n",
       "3                      NaN                  NaN                        NaN  \n",
       "4                      NaN                  NaN                        NaN  \n",
       "...                    ...                  ...                        ...  \n",
       "16594                  NaN                  NaN                        NaN  \n",
       "16595                  NaN                  NaN                        NaN  \n",
       "16596                  NaN                  NaN                        NaN  \n",
       "16597                  NaN                  NaN                        NaN  \n",
       "16598                  NaN                  NaN                        NaN  \n",
       "\n",
       "[16599 rows x 17 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagged_merged_data(data, seq_length=28):\n",
    "    X = []\n",
    "    y = []\n",
    "    for _, group in data.groupby([\"lat\", \"lon\"]):\n",
    "        group = group.sort_values(\"year\")\n",
    "        features = group.drop(columns=[\"year\", \"month\", \"lat\", \"lon\", \"States\", \"Usage\"])\n",
    "        target = group[\"Usage\"]\n",
    "        for row in range(len(features) - seq_length):\n",
    "            X.append(features.iloc[row:row+seq_length].values)\n",
    "            y.append(target.iloc[row+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "merged_X, targt_y = lagged_merged_data(merged_df, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnergyPrediction(nn.Module):\n",
    "    def __init__(self, encoder, input_size, hidden_size=64):\n",
    "        super(EnergyPrediction, self).__init__()\n",
    "        self.encoder = encoder.encoder\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded_x, _ = self.encoder(x)  # [batch, seq_len, hidden*2]\n",
    "        x = self.regressor(encoded_x[:, -1, :])  # Use last timestep\n",
    "        return x  # [batch, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "EnergyPrediction(\n",
      "  (encoder): LSTM(11, 64, batch_first=True, bidirectional=True)\n",
      "  (regressor): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "EnergyPrediction                         [1, 1]                    --\n",
      "├─LSTM: 1-1                              [1, 14, 128]              39,424\n",
      "├─Sequential: 1-2                        [1, 1]                    --\n",
      "│    └─Linear: 2-1                       [1, 64]                   8,256\n",
      "│    └─ReLU: 2-2                         [1, 64]                   --\n",
      "│    └─Linear: 2-3                       [1, 1]                    65\n",
      "==========================================================================================\n",
      "Total params: 47,745\n",
      "Trainable params: 47,745\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 0.56\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.19\n",
      "Estimated Total Size (MB): 0.21\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kvv/miniconda3/envs/nn/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kvv/miniconda3/envs/nn/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([27])) that is different to the input size (torch.Size([27, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "batch_size = 32\n",
    "lr = 0.001\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(merged_X, dtype=torch.float32), torch.tensor(targt_y, dtype=torch.float32))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "energy_model = EnergyPrediction(climate_pretrained_model, input_size=merged_X.shape[2]).to(device)\n",
    "print(\"Model Summary:\")\n",
    "print(energy_model)\n",
    "print(summary(energy_model, input_size=(1, 14, merged_X.shape[2])))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(energy_model.parameters(), lr=lr)\n",
    "energy_model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "        inputs, targets = batch[0].to(device), batch[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = energy_model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Loss: nan\n"
     ]
    }
   ],
   "source": [
    "for param in energy_model.encoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "        inputs, targets = batch[0].to(device), batch[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = energy_model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
